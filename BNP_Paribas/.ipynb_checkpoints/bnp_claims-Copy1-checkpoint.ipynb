{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Thomas Balestri \n",
      "last updated: 2016-03-29 \n",
      "\n",
      "CPython 2.7.6\n",
      "IPython 4.0.1\n",
      "\n",
      "numpy 1.10.4\n",
      "pandas 0.17.1\n",
      "matplotlib 1.3.1\n",
      "scikit-learn 0.17\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Thomas Balestri' -u -d -v -p numpy,pandas,matplotlib,scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>v11</th>\n",
       "      <th>v12</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>v15</th>\n",
       "      <th>v16</th>\n",
       "      <th>v17</th>\n",
       "      <th>v18</th>\n",
       "      <th>v19</th>\n",
       "      <th>v20</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>v29</th>\n",
       "      <th>v30</th>\n",
       "      <th>v31</th>\n",
       "      <th>v32</th>\n",
       "      <th>v33</th>\n",
       "      <th>v34</th>\n",
       "      <th>v35</th>\n",
       "      <th>v36</th>\n",
       "      <th>v37</th>\n",
       "      <th>v38</th>\n",
       "      <th>v39</th>\n",
       "      <th>v40</th>\n",
       "      <th>v41</th>\n",
       "      <th>v42</th>\n",
       "      <th>v43</th>\n",
       "      <th>v44</th>\n",
       "      <th>v45</th>\n",
       "      <th>v46</th>\n",
       "      <th>v47</th>\n",
       "      <th>v48</th>\n",
       "      <th>v49</th>\n",
       "      <th>v50</th>\n",
       "      <th>v51</th>\n",
       "      <th>v52</th>\n",
       "      <th>v53</th>\n",
       "      <th>v54</th>\n",
       "      <th>v55</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58</th>\n",
       "      <th>v59</th>\n",
       "      <th>v60</th>\n",
       "      <th>v61</th>\n",
       "      <th>v62</th>\n",
       "      <th>v63</th>\n",
       "      <th>v64</th>\n",
       "      <th>v65</th>\n",
       "      <th>v66</th>\n",
       "      <th>v67</th>\n",
       "      <th>v68</th>\n",
       "      <th>v69</th>\n",
       "      <th>v70</th>\n",
       "      <th>v71</th>\n",
       "      <th>v72</th>\n",
       "      <th>v73</th>\n",
       "      <th>v74</th>\n",
       "      <th>v75</th>\n",
       "      <th>v76</th>\n",
       "      <th>v77</th>\n",
       "      <th>v78</th>\n",
       "      <th>v79</th>\n",
       "      <th>v80</th>\n",
       "      <th>v81</th>\n",
       "      <th>v82</th>\n",
       "      <th>v83</th>\n",
       "      <th>v84</th>\n",
       "      <th>v85</th>\n",
       "      <th>v86</th>\n",
       "      <th>v87</th>\n",
       "      <th>v88</th>\n",
       "      <th>v89</th>\n",
       "      <th>v90</th>\n",
       "      <th>v91</th>\n",
       "      <th>v92</th>\n",
       "      <th>v93</th>\n",
       "      <th>v94</th>\n",
       "      <th>v95</th>\n",
       "      <th>v96</th>\n",
       "      <th>v97</th>\n",
       "      <th>v98</th>\n",
       "      <th>v99</th>\n",
       "      <th>v100</th>\n",
       "      <th>v101</th>\n",
       "      <th>v102</th>\n",
       "      <th>v103</th>\n",
       "      <th>v104</th>\n",
       "      <th>v105</th>\n",
       "      <th>v106</th>\n",
       "      <th>v107</th>\n",
       "      <th>v108</th>\n",
       "      <th>v109</th>\n",
       "      <th>v110</th>\n",
       "      <th>v111</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v114</th>\n",
       "      <th>v115</th>\n",
       "      <th>v116</th>\n",
       "      <th>v117</th>\n",
       "      <th>v118</th>\n",
       "      <th>v119</th>\n",
       "      <th>v120</th>\n",
       "      <th>v121</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v125</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v129</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>C</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>0.503281</td>\n",
       "      <td>16.434108</td>\n",
       "      <td>6.085711</td>\n",
       "      <td>2.866830</td>\n",
       "      <td>11.636387</td>\n",
       "      <td>1.355013</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>3.670350</td>\n",
       "      <td>0.106720</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>18.869283</td>\n",
       "      <td>7.730923</td>\n",
       "      <td>XDX</td>\n",
       "      <td>-1.716131e-08</td>\n",
       "      <td>C</td>\n",
       "      <td>0.139412</td>\n",
       "      <td>1.720818</td>\n",
       "      <td>3.393503</td>\n",
       "      <td>0.590122</td>\n",
       "      <td>8.880867</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>1.083033</td>\n",
       "      <td>1.010829</td>\n",
       "      <td>7.270147</td>\n",
       "      <td>8.375452</td>\n",
       "      <td>11.326592</td>\n",
       "      <td>0.454546</td>\n",
       "      <td>0</td>\n",
       "      <td>4.012088</td>\n",
       "      <td>7.711453</td>\n",
       "      <td>7.653429</td>\n",
       "      <td>12.707581</td>\n",
       "      <td>2.015505</td>\n",
       "      <td>10.498338</td>\n",
       "      <td>9.848672</td>\n",
       "      <td>0.113561</td>\n",
       "      <td>C</td>\n",
       "      <td>12.171733</td>\n",
       "      <td>8.086643</td>\n",
       "      <td>0.899420</td>\n",
       "      <td>7.277792</td>\n",
       "      <td>G</td>\n",
       "      <td>16.747968</td>\n",
       "      <td>0.037096</td>\n",
       "      <td>1.299638</td>\n",
       "      <td>DI</td>\n",
       "      <td>3.971118</td>\n",
       "      <td>0.529802</td>\n",
       "      <td>10.890984</td>\n",
       "      <td>1.588448</td>\n",
       "      <td>15.858152</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153461</td>\n",
       "      <td>6.363189</td>\n",
       "      <td>18.303925</td>\n",
       "      <td>C</td>\n",
       "      <td>9.314079</td>\n",
       "      <td>15.231789</td>\n",
       "      <td>17.142857</td>\n",
       "      <td>11.784549</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1.614988</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>2.230940</td>\n",
       "      <td>7.292418</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>E</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.528326</td>\n",
       "      <td>8.861647</td>\n",
       "      <td>0.649820</td>\n",
       "      <td>1.299638</td>\n",
       "      <td>1.707317</td>\n",
       "      <td>0.866426</td>\n",
       "      <td>9.551836</td>\n",
       "      <td>3.321300</td>\n",
       "      <td>0.095678</td>\n",
       "      <td>0.905342</td>\n",
       "      <td>A</td>\n",
       "      <td>0.442252</td>\n",
       "      <td>5.814018</td>\n",
       "      <td>3.517720</td>\n",
       "      <td>0.462019</td>\n",
       "      <td>7.436824</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>8.877414</td>\n",
       "      <td>1.191337</td>\n",
       "      <td>19.470199</td>\n",
       "      <td>8.389237</td>\n",
       "      <td>2.757375</td>\n",
       "      <td>4.374296</td>\n",
       "      <td>1.574039</td>\n",
       "      <td>0.007294</td>\n",
       "      <td>12.579184</td>\n",
       "      <td>E</td>\n",
       "      <td>2.382692</td>\n",
       "      <td>3.930922</td>\n",
       "      <td>B</td>\n",
       "      <td>0.433213</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.634907</td>\n",
       "      <td>2.857144</td>\n",
       "      <td>1.951220</td>\n",
       "      <td>6.592012</td>\n",
       "      <td>5.909091</td>\n",
       "      <td>-6.297423e-07</td>\n",
       "      <td>1.059603</td>\n",
       "      <td>0.803572</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>AU</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>2.024285</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636365</td>\n",
       "      <td>2.857144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.507647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.636386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.763110</td>\n",
       "      <td>GUV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>3.056144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.615077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.579479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.305766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.449959</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.379210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.129469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2.544736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.053353</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.277655</td>\n",
       "      <td>3.430691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.848004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.678584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.303967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.505335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>1.825361</td>\n",
       "      <td>4.247858</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>G</td>\n",
       "      <td>10.308044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.595357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.957825</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>C</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>14.756098</td>\n",
       "      <td>6.384670</td>\n",
       "      <td>2.505589</td>\n",
       "      <td>9.603542</td>\n",
       "      <td>1.984127</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>3.170847</td>\n",
       "      <td>0.244541</td>\n",
       "      <td>0.144258</td>\n",
       "      <td>17.952332</td>\n",
       "      <td>5.245035</td>\n",
       "      <td>FQ</td>\n",
       "      <td>-2.785053e-07</td>\n",
       "      <td>E</td>\n",
       "      <td>0.113997</td>\n",
       "      <td>2.244897</td>\n",
       "      <td>5.306122</td>\n",
       "      <td>0.836005</td>\n",
       "      <td>7.499999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>1.454082</td>\n",
       "      <td>1.734693</td>\n",
       "      <td>4.043864</td>\n",
       "      <td>7.959184</td>\n",
       "      <td>12.730517</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0</td>\n",
       "      <td>7.378964</td>\n",
       "      <td>13.077201</td>\n",
       "      <td>6.173469</td>\n",
       "      <td>12.346939</td>\n",
       "      <td>2.926830</td>\n",
       "      <td>8.897561</td>\n",
       "      <td>5.343819</td>\n",
       "      <td>0.126035</td>\n",
       "      <td>C</td>\n",
       "      <td>12.711328</td>\n",
       "      <td>6.836734</td>\n",
       "      <td>0.604504</td>\n",
       "      <td>9.637627</td>\n",
       "      <td>F</td>\n",
       "      <td>15.102041</td>\n",
       "      <td>0.085573</td>\n",
       "      <td>0.765305</td>\n",
       "      <td>AS</td>\n",
       "      <td>4.030613</td>\n",
       "      <td>4.277456</td>\n",
       "      <td>9.105481</td>\n",
       "      <td>2.151361</td>\n",
       "      <td>16.075602</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123643</td>\n",
       "      <td>5.517949</td>\n",
       "      <td>16.377205</td>\n",
       "      <td>A</td>\n",
       "      <td>8.367347</td>\n",
       "      <td>11.040463</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>8.460654</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>2.413618</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>1.963971</td>\n",
       "      <td>5.918368</td>\n",
       "      <td>11.764705</td>\n",
       "      <td>E</td>\n",
       "      <td>3.333334</td>\n",
       "      <td>10.194433</td>\n",
       "      <td>8.266200</td>\n",
       "      <td>1.530611</td>\n",
       "      <td>1.530613</td>\n",
       "      <td>2.429906</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>8.447465</td>\n",
       "      <td>3.367346</td>\n",
       "      <td>0.111388</td>\n",
       "      <td>0.811447</td>\n",
       "      <td>G</td>\n",
       "      <td>0.271480</td>\n",
       "      <td>5.156559</td>\n",
       "      <td>4.214944</td>\n",
       "      <td>0.309657</td>\n",
       "      <td>5.663265</td>\n",
       "      <td>5.974026</td>\n",
       "      <td>11.588858</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>15.491329</td>\n",
       "      <td>5.879353</td>\n",
       "      <td>3.292788</td>\n",
       "      <td>5.924457</td>\n",
       "      <td>1.668401</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>11.670572</td>\n",
       "      <td>C</td>\n",
       "      <td>1.375753</td>\n",
       "      <td>1.184211</td>\n",
       "      <td>B</td>\n",
       "      <td>3.367348</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.205561</td>\n",
       "      <td>12.941177</td>\n",
       "      <td>3.129253</td>\n",
       "      <td>3.478911</td>\n",
       "      <td>6.233767</td>\n",
       "      <td>-2.792745e-07</td>\n",
       "      <td>2.138728</td>\n",
       "      <td>2.238806</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>AE</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>1.120468</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>C</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>8.965516</td>\n",
       "      <td>6.542669</td>\n",
       "      <td>16.347483</td>\n",
       "      <td>9.646653</td>\n",
       "      <td>3.903302</td>\n",
       "      <td>14.094723</td>\n",
       "      <td>1.945044</td>\n",
       "      <td>5.517242</td>\n",
       "      <td>3.610789</td>\n",
       "      <td>1.224114</td>\n",
       "      <td>0.231630</td>\n",
       "      <td>18.376407</td>\n",
       "      <td>7.517125</td>\n",
       "      <td>ACUE</td>\n",
       "      <td>-4.805344e-07</td>\n",
       "      <td>D</td>\n",
       "      <td>0.148843</td>\n",
       "      <td>1.308269</td>\n",
       "      <td>2.303640</td>\n",
       "      <td>8.926662</td>\n",
       "      <td>8.874521</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>1.587644</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>8.703550</td>\n",
       "      <td>8.898468</td>\n",
       "      <td>11.302795</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.287322</td>\n",
       "      <td>11.523045</td>\n",
       "      <td>7.931035</td>\n",
       "      <td>12.935823</td>\n",
       "      <td>1.470878</td>\n",
       "      <td>12.708574</td>\n",
       "      <td>9.670823</td>\n",
       "      <td>0.108387</td>\n",
       "      <td>C</td>\n",
       "      <td>12.194855</td>\n",
       "      <td>8.591954</td>\n",
       "      <td>3.329176</td>\n",
       "      <td>4.780357</td>\n",
       "      <td>H</td>\n",
       "      <td>16.621695</td>\n",
       "      <td>0.139721</td>\n",
       "      <td>1.178161</td>\n",
       "      <td>BW</td>\n",
       "      <td>3.965517</td>\n",
       "      <td>1.732102</td>\n",
       "      <td>11.777912</td>\n",
       "      <td>1.229246</td>\n",
       "      <td>15.927390</td>\n",
       "      <td>1</td>\n",
       "      <td>0.140260</td>\n",
       "      <td>6.292979</td>\n",
       "      <td>17.011645</td>\n",
       "      <td>A</td>\n",
       "      <td>9.703065</td>\n",
       "      <td>18.568129</td>\n",
       "      <td>9.425288</td>\n",
       "      <td>13.594728</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>2.272541</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>2.188198</td>\n",
       "      <td>8.213602</td>\n",
       "      <td>13.448277</td>\n",
       "      <td>B</td>\n",
       "      <td>1.947261</td>\n",
       "      <td>4.797873</td>\n",
       "      <td>13.315819</td>\n",
       "      <td>1.681034</td>\n",
       "      <td>1.379310</td>\n",
       "      <td>1.587045</td>\n",
       "      <td>1.242817</td>\n",
       "      <td>10.747144</td>\n",
       "      <td>1.408046</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>1.042425</td>\n",
       "      <td>B</td>\n",
       "      <td>0.763925</td>\n",
       "      <td>5.498902</td>\n",
       "      <td>3.423944</td>\n",
       "      <td>0.832518</td>\n",
       "      <td>7.375480</td>\n",
       "      <td>6.746988</td>\n",
       "      <td>6.942002</td>\n",
       "      <td>1.334611</td>\n",
       "      <td>18.256352</td>\n",
       "      <td>8.507281</td>\n",
       "      <td>2.503055</td>\n",
       "      <td>4.872157</td>\n",
       "      <td>2.573664</td>\n",
       "      <td>0.113967</td>\n",
       "      <td>12.554274</td>\n",
       "      <td>B</td>\n",
       "      <td>2.230754</td>\n",
       "      <td>1.990131</td>\n",
       "      <td>B</td>\n",
       "      <td>2.643678</td>\n",
       "      <td>J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.777666</td>\n",
       "      <td>10.574713</td>\n",
       "      <td>1.511063</td>\n",
       "      <td>4.949609</td>\n",
       "      <td>7.180722</td>\n",
       "      <td>5.655086e-01</td>\n",
       "      <td>1.166281</td>\n",
       "      <td>1.956521</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>CJ</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1.990847</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.320087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.991098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.414567</td>\n",
       "      <td>HIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.083151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.138920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.364536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>14.097099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.856791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.359993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.216077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.916255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.351426</td>\n",
       "      <td>AYX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0.218458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.496613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.497964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.903915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262632</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.653583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.131278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.276524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.521160</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.978375</td>\n",
       "      <td>3.811356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.618443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.116390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.970103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1.763765</td>\n",
       "      <td>2.442616</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "      <td>15.750502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.851677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049861</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.536222</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899806</td>\n",
       "      <td>7.312995</td>\n",
       "      <td>C</td>\n",
       "      <td>3.494148</td>\n",
       "      <td>9.946200</td>\n",
       "      <td>1.926070</td>\n",
       "      <td>1.770427</td>\n",
       "      <td>0.066251</td>\n",
       "      <td>5.011287</td>\n",
       "      <td>2.341356</td>\n",
       "      <td>16.274510</td>\n",
       "      <td>7.711174</td>\n",
       "      <td>5.915588</td>\n",
       "      <td>12.148604</td>\n",
       "      <td>1.968303</td>\n",
       "      <td>6.601941</td>\n",
       "      <td>2.873974</td>\n",
       "      <td>0.484133</td>\n",
       "      <td>0.443661</td>\n",
       "      <td>17.226675</td>\n",
       "      <td>6.661479</td>\n",
       "      <td>NFD</td>\n",
       "      <td>7.813019e-07</td>\n",
       "      <td>E</td>\n",
       "      <td>0.180765</td>\n",
       "      <td>1.070040</td>\n",
       "      <td>1.566147</td>\n",
       "      <td>4.393842</td>\n",
       "      <td>7.928015</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>1.619651</td>\n",
       "      <td>2.003892</td>\n",
       "      <td>3.964911</td>\n",
       "      <td>8.735408</td>\n",
       "      <td>13.967877</td>\n",
       "      <td>0.549451</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031587</td>\n",
       "      <td>14.787641</td>\n",
       "      <td>7.266536</td>\n",
       "      <td>14.445526</td>\n",
       "      <td>1.307190</td>\n",
       "      <td>11.765638</td>\n",
       "      <td>9.406689</td>\n",
       "      <td>0.110774</td>\n",
       "      <td>C</td>\n",
       "      <td>13.256878</td>\n",
       "      <td>8.365759</td>\n",
       "      <td>0.133520</td>\n",
       "      <td>6.368555</td>\n",
       "      <td>A</td>\n",
       "      <td>16.760736</td>\n",
       "      <td>0.097693</td>\n",
       "      <td>1.721789</td>\n",
       "      <td>AS</td>\n",
       "      <td>3.677042</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>12.858752</td>\n",
       "      <td>0.980870</td>\n",
       "      <td>15.067893</td>\n",
       "      <td>2</td>\n",
       "      <td>0.164415</td>\n",
       "      <td>5.175563</td>\n",
       "      <td>15.655942</td>\n",
       "      <td>A</td>\n",
       "      <td>8.929960</td>\n",
       "      <td>19.124088</td>\n",
       "      <td>11.456310</td>\n",
       "      <td>14.152569</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>2.519063</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>1.709188</td>\n",
       "      <td>7.354085</td>\n",
       "      <td>12.427184</td>\n",
       "      <td>E</td>\n",
       "      <td>1.534989</td>\n",
       "      <td>6.328159</td>\n",
       "      <td>3.490951</td>\n",
       "      <td>1.867705</td>\n",
       "      <td>1.984436</td>\n",
       "      <td>2.591876</td>\n",
       "      <td>1.123541</td>\n",
       "      <td>10.999548</td>\n",
       "      <td>1.147860</td>\n",
       "      <td>0.075958</td>\n",
       "      <td>1.343752</td>\n",
       "      <td>B</td>\n",
       "      <td>0.766422</td>\n",
       "      <td>5.875069</td>\n",
       "      <td>5.841754</td>\n",
       "      <td>0.863301</td>\n",
       "      <td>6.643969</td>\n",
       "      <td>6.043957</td>\n",
       "      <td>6.079678</td>\n",
       "      <td>1.301881</td>\n",
       "      <td>19.036496</td>\n",
       "      <td>7.492828</td>\n",
       "      <td>2.511898</td>\n",
       "      <td>6.310835</td>\n",
       "      <td>4.697276</td>\n",
       "      <td>0.047703</td>\n",
       "      <td>11.075756</td>\n",
       "      <td>B</td>\n",
       "      <td>2.254819</td>\n",
       "      <td>5.180922</td>\n",
       "      <td>B</td>\n",
       "      <td>2.568094</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.010082</td>\n",
       "      <td>8.543690</td>\n",
       "      <td>1.349693</td>\n",
       "      <td>12.168719</td>\n",
       "      <td>6.593406</td>\n",
       "      <td>1.532727e+00</td>\n",
       "      <td>0.846716</td>\n",
       "      <td>2.232558</td>\n",
       "      <td>3.476299</td>\n",
       "      <td>1.992594</td>\n",
       "      <td>0.083758</td>\n",
       "      <td>BJ</td>\n",
       "      <td>3.276100</td>\n",
       "      <td>1.623298</td>\n",
       "      <td>2.266575</td>\n",
       "      <td>0</td>\n",
       "      <td>2.263736</td>\n",
       "      <td>0.970873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.838074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.424482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.793945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.806704</td>\n",
       "      <td>AHBW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.077506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.034513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.682121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>18.705610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2.078651</td>\n",
       "      <td>8.462619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.739030</td>\n",
       "      <td>5.265636</td>\n",
       "      <td>1.573033</td>\n",
       "      <td>2.303371</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>4.463894</td>\n",
       "      <td>16.050955</td>\n",
       "      <td>8.715047</td>\n",
       "      <td>2.348053</td>\n",
       "      <td>12.603403</td>\n",
       "      <td>1.580461</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>3.052132</td>\n",
       "      <td>0.139939</td>\n",
       "      <td>0.180616</td>\n",
       "      <td>17.754603</td>\n",
       "      <td>6.034953</td>\n",
       "      <td>GKQ</td>\n",
       "      <td>-3.643173e-07</td>\n",
       "      <td>E</td>\n",
       "      <td>0.058906</td>\n",
       "      <td>1.647940</td>\n",
       "      <td>3.089888</td>\n",
       "      <td>0.759034</td>\n",
       "      <td>8.146068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.264045</td>\n",
       "      <td>1.348315</td>\n",
       "      <td>6.952621</td>\n",
       "      <td>8.089888</td>\n",
       "      <td>12.754314</td>\n",
       "      <td>0.975611</td>\n",
       "      <td>0</td>\n",
       "      <td>3.169000</td>\n",
       "      <td>12.199552</td>\n",
       "      <td>7.078652</td>\n",
       "      <td>11.741573</td>\n",
       "      <td>2.038216</td>\n",
       "      <td>10.173000</td>\n",
       "      <td>7.936837</td>\n",
       "      <td>0.085176</td>\n",
       "      <td>D</td>\n",
       "      <td>12.940907</td>\n",
       "      <td>7.921348</td>\n",
       "      <td>1.675592</td>\n",
       "      <td>8.851832</td>\n",
       "      <td>H</td>\n",
       "      <td>16.551725</td>\n",
       "      <td>0.015391</td>\n",
       "      <td>1.179776</td>\n",
       "      <td>AF</td>\n",
       "      <td>4.382023</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>10.022723</td>\n",
       "      <td>1.441947</td>\n",
       "      <td>15.555608</td>\n",
       "      <td>0</td>\n",
       "      <td>0.067720</td>\n",
       "      <td>5.406643</td>\n",
       "      <td>16.856447</td>\n",
       "      <td>B</td>\n",
       "      <td>8.820225</td>\n",
       "      <td>15.656566</td>\n",
       "      <td>11.666666</td>\n",
       "      <td>9.727713</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>1.990445</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>1.840990</td>\n",
       "      <td>7.078652</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>P</td>\n",
       "      <td>2.962964</td>\n",
       "      <td>10.253182</td>\n",
       "      <td>8.231174</td>\n",
       "      <td>1.011235</td>\n",
       "      <td>1.348314</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.926967</td>\n",
       "      <td>6.961616</td>\n",
       "      <td>2.471910</td>\n",
       "      <td>0.040216</td>\n",
       "      <td>0.910867</td>\n",
       "      <td>C</td>\n",
       "      <td>0.585040</td>\n",
       "      <td>5.004810</td>\n",
       "      <td>3.094116</td>\n",
       "      <td>0.632525</td>\n",
       "      <td>6.741573</td>\n",
       "      <td>6.829269</td>\n",
       "      <td>9.823610</td>\n",
       "      <td>0.720974</td>\n",
       "      <td>19.494949</td>\n",
       "      <td>6.672091</td>\n",
       "      <td>1.780246</td>\n",
       "      <td>4.679944</td>\n",
       "      <td>1.653404</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>11.460973</td>\n",
       "      <td>D</td>\n",
       "      <td>1.194403</td>\n",
       "      <td>1.151316</td>\n",
       "      <td>C</td>\n",
       "      <td>1.685393</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.536835</td>\n",
       "      <td>8.333332</td>\n",
       "      <td>1.931034</td>\n",
       "      <td>3.419186</td>\n",
       "      <td>7.804877</td>\n",
       "      <td>5.182423e-01</td>\n",
       "      <td>1.414142</td>\n",
       "      <td>1.276595</td>\n",
       "      <td>8.148148</td>\n",
       "      <td>1.875560</td>\n",
       "      <td>0.018659</td>\n",
       "      <td>S</td>\n",
       "      <td>1.159637</td>\n",
       "      <td>5.582865</td>\n",
       "      <td>1.105283</td>\n",
       "      <td>0</td>\n",
       "      <td>1.170731</td>\n",
       "      <td>3.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1.144802</td>\n",
       "      <td>5.880606</td>\n",
       "      <td>C</td>\n",
       "      <td>3.244469</td>\n",
       "      <td>9.538384</td>\n",
       "      <td>2.500001</td>\n",
       "      <td>1.559405</td>\n",
       "      <td>0.412610</td>\n",
       "      <td>9.977529</td>\n",
       "      <td>2.363238</td>\n",
       "      <td>16.091401</td>\n",
       "      <td>7.417853</td>\n",
       "      <td>4.176949</td>\n",
       "      <td>13.790046</td>\n",
       "      <td>2.319558</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>2.768652</td>\n",
       "      <td>0.812777</td>\n",
       "      <td>0.271822</td>\n",
       "      <td>18.410067</td>\n",
       "      <td>8.312447</td>\n",
       "      <td>PYF</td>\n",
       "      <td>3.955979e-08</td>\n",
       "      <td>C</td>\n",
       "      <td>0.509588</td>\n",
       "      <td>1.168523</td>\n",
       "      <td>1.410891</td>\n",
       "      <td>6.908275</td>\n",
       "      <td>9.059405</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>2.060643</td>\n",
       "      <td>2.475247</td>\n",
       "      <td>6.498729</td>\n",
       "      <td>9.603961</td>\n",
       "      <td>14.658608</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075258</td>\n",
       "      <td>10.803126</td>\n",
       "      <td>8.279704</td>\n",
       "      <td>13.267328</td>\n",
       "      <td>1.238725</td>\n",
       "      <td>10.295850</td>\n",
       "      <td>12.480398</td>\n",
       "      <td>0.343973</td>\n",
       "      <td>I</td>\n",
       "      <td>13.982603</td>\n",
       "      <td>8.954208</td>\n",
       "      <td>0.993324</td>\n",
       "      <td>6.682327</td>\n",
       "      <td>A</td>\n",
       "      <td>16.489072</td>\n",
       "      <td>0.232800</td>\n",
       "      <td>1.707922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.811880</td>\n",
       "      <td>6.417392</td>\n",
       "      <td>13.204338</td>\n",
       "      <td>1.055074</td>\n",
       "      <td>13.528267</td>\n",
       "      <td>3</td>\n",
       "      <td>0.390694</td>\n",
       "      <td>4.874554</td>\n",
       "      <td>16.499231</td>\n",
       "      <td>A</td>\n",
       "      <td>10.290842</td>\n",
       "      <td>19.495653</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>15.052754</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>2.781119</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>1.668671</td>\n",
       "      <td>8.644803</td>\n",
       "      <td>13.099999</td>\n",
       "      <td>C</td>\n",
       "      <td>2.651686</td>\n",
       "      <td>7.017475</td>\n",
       "      <td>3.679445</td>\n",
       "      <td>2.431930</td>\n",
       "      <td>2.190594</td>\n",
       "      <td>2.747749</td>\n",
       "      <td>1.512996</td>\n",
       "      <td>12.324700</td>\n",
       "      <td>0.878712</td>\n",
       "      <td>0.171153</td>\n",
       "      <td>1.189657</td>\n",
       "      <td>A</td>\n",
       "      <td>1.022954</td>\n",
       "      <td>5.432639</td>\n",
       "      <td>3.152513</td>\n",
       "      <td>1.158783</td>\n",
       "      <td>7.469059</td>\n",
       "      <td>7.380952</td>\n",
       "      <td>5.772735</td>\n",
       "      <td>1.179868</td>\n",
       "      <td>13.582609</td>\n",
       "      <td>7.197289</td>\n",
       "      <td>3.694347</td>\n",
       "      <td>4.389466</td>\n",
       "      <td>3.001609</td>\n",
       "      <td>0.278599</td>\n",
       "      <td>10.064205</td>\n",
       "      <td>E</td>\n",
       "      <td>2.240590</td>\n",
       "      <td>3.837530</td>\n",
       "      <td>A</td>\n",
       "      <td>3.972772</td>\n",
       "      <td>J</td>\n",
       "      <td>P</td>\n",
       "      <td>13.434123</td>\n",
       "      <td>10.700001</td>\n",
       "      <td>1.270491</td>\n",
       "      <td>10.719493</td>\n",
       "      <td>8.174604</td>\n",
       "      <td>8.931283e+00</td>\n",
       "      <td>0.434782</td>\n",
       "      <td>2.715964</td>\n",
       "      <td>7.325843</td>\n",
       "      <td>4.896617</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>E</td>\n",
       "      <td>1.344550</td>\n",
       "      <td>1.601176</td>\n",
       "      <td>1.928009</td>\n",
       "      <td>0</td>\n",
       "      <td>3.174603</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target        v1        v2   v3        v4         v5        v6  \\\n",
       "0   3       1  1.335739  8.727474    C  3.921026   7.915266  2.599278   \n",
       "1   4       1       NaN       NaN    C       NaN   9.191265       NaN   \n",
       "2   5       1  0.943877  5.310079    C  4.410969   5.326159  3.979592   \n",
       "3   6       1  0.797415  8.304757    C  4.225930  11.627438  2.097700   \n",
       "4   8       1       NaN       NaN    C       NaN        NaN       NaN   \n",
       "5   9       0       NaN       NaN    C       NaN   8.856791       NaN   \n",
       "6  12       0  0.899806  7.312995    C  3.494148   9.946200  1.926070   \n",
       "7  21       1       NaN       NaN    C       NaN        NaN       NaN   \n",
       "8  22       0  2.078651  8.462619  NaN  3.739030   5.265636  1.573033   \n",
       "9  23       1  1.144802  5.880606    C  3.244469   9.538384  2.500001   \n",
       "\n",
       "         v7        v8         v9       v10        v11       v12       v13  \\\n",
       "0  3.176895  0.012941   9.999999  0.503281  16.434108  6.085711  2.866830   \n",
       "1       NaN  2.301630        NaN  1.312910        NaN  6.507647       NaN   \n",
       "2  3.928571  0.019645  12.666667  0.765864  14.756098  6.384670  2.505589   \n",
       "3  1.987549  0.171947   8.965516  6.542669  16.347483  9.646653  3.903302   \n",
       "4       NaN       NaN        NaN  1.050328        NaN  6.320087       NaN   \n",
       "5       NaN  0.359993        NaN  1.050328        NaN  6.216077       NaN   \n",
       "6  1.770427  0.066251   5.011287  2.341356  16.274510  7.711174  5.915588   \n",
       "7       NaN       NaN        NaN  1.838074        NaN  6.424482       NaN   \n",
       "8  2.303371  0.015869  11.111111  4.463894  16.050955  8.715047  2.348053   \n",
       "9  1.559405  0.412610   9.977529  2.363238  16.091401  7.417853  4.176949   \n",
       "\n",
       "         v14       v15       v16       v17       v18       v19        v20  \\\n",
       "0  11.636387  1.355013  8.571429  3.670350  0.106720  0.148883  18.869283   \n",
       "1  11.636386       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "2   9.603542  1.984127  5.882353  3.170847  0.244541  0.144258  17.952332   \n",
       "3  14.094723  1.945044  5.517242  3.610789  1.224114  0.231630  18.376407   \n",
       "4  10.991098       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "5  11.916255       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "6  12.148604  1.968303  6.601941  2.873974  0.484133  0.443661  17.226675   \n",
       "7  12.793945       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "8  12.603403  1.580461  6.666667  3.052132  0.139939  0.180616  17.754603   \n",
       "9  13.790046  2.319558  5.900000  2.768652  0.812777  0.271822  18.410067   \n",
       "\n",
       "        v21   v22           v23 v24       v25       v26       v27       v28  \\\n",
       "0  7.730923   XDX -1.716131e-08   C  0.139412  1.720818  3.393503  0.590122   \n",
       "1  6.763110   GUV           NaN   C  3.056144       NaN       NaN       NaN   \n",
       "2  5.245035    FQ -2.785053e-07   E  0.113997  2.244897  5.306122  0.836005   \n",
       "3  7.517125  ACUE -4.805344e-07   D  0.148843  1.308269  2.303640  8.926662   \n",
       "4  6.414567   HIT           NaN   E       NaN       NaN       NaN       NaN   \n",
       "5  7.351426   AYX           NaN   A  0.218458       NaN       NaN       NaN   \n",
       "6  6.661479   NFD  7.813019e-07   E  0.180765  1.070040  1.566147  4.393842   \n",
       "7  7.806704  AHBW           NaN   D       NaN       NaN       NaN       NaN   \n",
       "8  6.034953   GKQ -3.643173e-07   E  0.058906  1.647940  3.089888  0.759034   \n",
       "9  8.312447   PYF  3.955979e-08   C  0.509588  1.168523  1.410891  6.908275   \n",
       "\n",
       "        v29  v30  v31       v32       v33        v34       v35        v36  \\\n",
       "0  8.880867    C    A  1.083033  1.010829   7.270147  8.375452  11.326592   \n",
       "1       NaN    C    A       NaN       NaN   3.615077       NaN  14.579479   \n",
       "2  7.499999  NaN    A  1.454082  1.734693   4.043864  7.959184  12.730517   \n",
       "3  8.874521    C    B  1.587644  1.666667   8.703550  8.898468  11.302795   \n",
       "4       NaN  NaN    A       NaN       NaN   6.083151       NaN        NaN   \n",
       "5       NaN  NaN    A       NaN       NaN   7.496613       NaN  15.497964   \n",
       "6  7.928015    G    A  1.619651  2.003892   3.964911  8.735408  13.967877   \n",
       "7       NaN    C    A       NaN       NaN  11.077506       NaN        NaN   \n",
       "8  8.146068  NaN  NaN  1.264045  1.348315   6.952621  8.089888  12.754314   \n",
       "9  9.059405    C    A  2.060643  2.475247   6.498729  9.603961  14.658608   \n",
       "\n",
       "        v37  v38       v39        v40       v41        v42       v43  \\\n",
       "0  0.454546    0  4.012088   7.711453  7.653429  12.707581  2.015505   \n",
       "1       NaN    0       NaN  14.305766       NaN        NaN       NaN   \n",
       "2  0.259740    0  7.378964  13.077201  6.173469  12.346939  2.926830   \n",
       "3  0.433735    0  0.287322  11.523045  7.931035  12.935823  1.470878   \n",
       "4       NaN    0       NaN  10.138920       NaN        NaN       NaN   \n",
       "5       NaN    0       NaN   7.903915       NaN        NaN       NaN   \n",
       "6  0.549451    0  0.031587  14.787641  7.266536  14.445526  1.307190   \n",
       "7       NaN    0       NaN   3.034513       NaN        NaN       NaN   \n",
       "8  0.975611    0  3.169000  12.199552  7.078652  11.741573  2.038216   \n",
       "9  0.793651    0  0.075258  10.803126  8.279704  13.267328  1.238725   \n",
       "\n",
       "         v44        v45       v46 v47        v48       v49       v50  \\\n",
       "0  10.498338   9.848672  0.113561   C  12.171733  8.086643  0.899420   \n",
       "1        NaN        NaN  2.449959   E        NaN       NaN  1.379210   \n",
       "2   8.897561   5.343819  0.126035   C  12.711328  6.836734  0.604504   \n",
       "3  12.708574   9.670823  0.108387   C  12.194855  8.591954  3.329176   \n",
       "4        NaN        NaN       NaN   I        NaN       NaN  1.364536   \n",
       "5        NaN        NaN  0.262632   I        NaN       NaN  1.653583   \n",
       "6  11.765638   9.406689  0.110774   C  13.256878  8.365759  0.133520   \n",
       "7        NaN        NaN       NaN   I        NaN       NaN  2.682121   \n",
       "8  10.173000   7.936837  0.085176   D  12.940907  7.921348  1.675592   \n",
       "9  10.295850  12.480398  0.343973   I  13.982603  8.954208  0.993324   \n",
       "\n",
       "        v51 v52        v53       v54       v55  v56       v57       v58  \\\n",
       "0  7.277792   G  16.747968  0.037096  1.299638   DI  3.971118  0.529802   \n",
       "1       NaN   G        NaN  1.129469       NaN   DY       NaN       NaN   \n",
       "2  9.637627   F  15.102041  0.085573  0.765305   AS  4.030613  4.277456   \n",
       "3  4.780357   H  16.621695  0.139721  1.178161   BW  3.965517  1.732102   \n",
       "4       NaN   H        NaN       NaN       NaN  NaN       NaN       NaN   \n",
       "5       NaN   K        NaN  0.131278       NaN   DX       NaN       NaN   \n",
       "6  6.368555   A  16.760736  0.097693  1.721789   AS  3.677042  0.729927   \n",
       "7       NaN   C        NaN       NaN       NaN   DP       NaN       NaN   \n",
       "8  8.851832   H  16.551725  0.015391  1.179776   AF  4.382023  0.505051   \n",
       "9  6.682327   A  16.489072  0.232800  1.707922  NaN  3.811880  6.417392   \n",
       "\n",
       "         v59       v60        v61  v62       v63       v64        v65 v66  \\\n",
       "0  10.890984  1.588448  15.858152    1  0.153461  6.363189  18.303925   C   \n",
       "1        NaN       NaN        NaN    2  2.544736       NaN        NaN   A   \n",
       "2   9.105481  2.151361  16.075602    1  0.123643  5.517949  16.377205   A   \n",
       "3  11.777912  1.229246  15.927390    1  0.140260  6.292979  17.011645   A   \n",
       "4        NaN       NaN        NaN    1       NaN       NaN        NaN   C   \n",
       "5        NaN       NaN        NaN    1  0.276524       NaN        NaN   A   \n",
       "6  12.858752  0.980870  15.067893    2  0.164415  5.175563  15.655942   A   \n",
       "7        NaN       NaN        NaN    2       NaN       NaN        NaN   C   \n",
       "8  10.022723  1.441947  15.555608    0  0.067720  5.406643  16.856447   B   \n",
       "9  13.204338  1.055074  13.528267    3  0.390694  4.874554  16.499231   A   \n",
       "\n",
       "         v67        v68        v69        v70 v71  v72       v73 v74 v75  \\\n",
       "0   9.314079  15.231789  17.142857  11.784549   F    1  1.614988   B   D   \n",
       "1        NaN        NaN        NaN  12.053353   F    2       NaN   B   D   \n",
       "2   8.367347  11.040463   5.882353   8.460654   B    3  2.413618   B   B   \n",
       "3   9.703065  18.568129   9.425288  13.594728   F    2  2.272541   B   D   \n",
       "4        NaN        NaN        NaN        NaN   F    1       NaN   B   D   \n",
       "5        NaN        NaN        NaN  11.521160   F    1       NaN   B   D   \n",
       "6   8.929960  19.124088  11.456310  14.152569   F    2  2.519063   B   D   \n",
       "7        NaN        NaN        NaN        NaN   F    2       NaN   B   D   \n",
       "8   8.820225  15.656566  11.666666   9.727713   B    0  1.990445   B   B   \n",
       "9  10.290842  19.495653   9.200000  15.052754   F    3  2.781119   B   D   \n",
       "\n",
       "        v76       v77        v78 v79       v80        v81        v82  \\\n",
       "0  2.230940  7.292418   8.571429   E  3.000000   7.528326   8.861647   \n",
       "1       NaN       NaN        NaN   D       NaN   7.277655   3.430691   \n",
       "2  1.963971  5.918368  11.764705   E  3.333334  10.194433   8.266200   \n",
       "3  2.188198  8.213602  13.448277   B  1.947261   4.797873  13.315819   \n",
       "4       NaN       NaN        NaN   C       NaN        NaN        NaN   \n",
       "5       NaN       NaN        NaN   I       NaN   7.978375   3.811356   \n",
       "6  1.709188  7.354085  12.427184   E  1.534989   6.328159   3.490951   \n",
       "7       NaN       NaN        NaN   C       NaN        NaN        NaN   \n",
       "8  1.840990  7.078652  10.000000   P  2.962964  10.253182   8.231174   \n",
       "9  1.668671  8.644803  13.099999   C  2.651686   7.017475   3.679445   \n",
       "\n",
       "        v83       v84       v85       v86        v87       v88       v89  \\\n",
       "0  0.649820  1.299638  1.707317  0.866426   9.551836  3.321300  0.095678   \n",
       "1       NaN       NaN       NaN       NaN   9.848004       NaN  2.678584   \n",
       "2  1.530611  1.530613  2.429906  1.071429   8.447465  3.367346  0.111388   \n",
       "3  1.681034  1.379310  1.587045  1.242817  10.747144  1.408046  0.039051   \n",
       "4       NaN       NaN       NaN       NaN        NaN       NaN       NaN   \n",
       "5       NaN       NaN       NaN       NaN   9.618443       NaN  0.116390   \n",
       "6  1.867705  1.984436  2.591876  1.123541  10.999548  1.147860  0.075958   \n",
       "7       NaN       NaN       NaN       NaN        NaN       NaN       NaN   \n",
       "8  1.011235  1.348314  1.600000  0.926967   6.961616  2.471910  0.040216   \n",
       "9  2.431930  2.190594  2.747749  1.512996  12.324700  0.878712  0.171153   \n",
       "\n",
       "        v90 v91       v92       v93       v94       v95       v96       v97  \\\n",
       "0  0.905342   A  0.442252  5.814018  3.517720  0.462019  7.436824  5.454545   \n",
       "1       NaN   B       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2  0.811447   G  0.271480  5.156559  4.214944  0.309657  5.663265  5.974026   \n",
       "3  1.042425   B  0.763925  5.498902  3.423944  0.832518  7.375480  6.746988   \n",
       "4       NaN   G       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "5       NaN   G       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "6  1.343752   B  0.766422  5.875069  5.841754  0.863301  6.643969  6.043957   \n",
       "7       NaN   A       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "8  0.910867   C  0.585040  5.004810  3.094116  0.632525  6.741573  6.829269   \n",
       "9  1.189657   A  1.022954  5.432639  3.152513  1.158783  7.469059  7.380952   \n",
       "\n",
       "         v98       v99       v100      v101      v102      v103      v104  \\\n",
       "0   8.877414  1.191337  19.470199  8.389237  2.757375  4.374296  1.574039   \n",
       "1   8.303967       NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "2  11.588858  0.841837  15.491329  5.879353  3.292788  5.924457  1.668401   \n",
       "3   6.942002  1.334611  18.256352  8.507281  2.503055  4.872157  2.573664   \n",
       "4        NaN       NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "5   8.970103       NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "6   6.079678  1.301881  19.036496  7.492828  2.511898  6.310835  4.697276   \n",
       "7        NaN       NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "8   9.823610  0.720974  19.494949  6.672091  1.780246  4.679944  1.653404   \n",
       "9   5.772735  1.179868  13.582609  7.197289  3.694347  4.389466  3.001609   \n",
       "\n",
       "       v105       v106 v107      v108      v109 v110      v111 v112 v113  \\\n",
       "0  0.007294  12.579184    E  2.382692  3.930922    B  0.433213    O  NaN   \n",
       "1  1.505335        NaN    B  1.825361  4.247858    A       NaN    U    G   \n",
       "2  0.008275  11.670572    C  1.375753  1.184211    B  3.367348    S  NaN   \n",
       "3  0.113967  12.554274    B  2.230754  1.990131    B  2.643678    J  NaN   \n",
       "4       NaN        NaN    C       NaN       NaN    A       NaN    T    G   \n",
       "5  0.193530        NaN    C  1.763765  2.442616    A       NaN    D    X   \n",
       "6  0.047703  11.075756    B  2.254819  5.180922    B  2.568094    I  NaN   \n",
       "7       NaN        NaN    E       NaN       NaN    A       NaN    F    M   \n",
       "8  0.006071  11.460973    D  1.194403  1.151316    C  1.685393    L  NaN   \n",
       "9  0.278599  10.064205    E  2.240590  3.837530    A  3.972772    J    P   \n",
       "\n",
       "        v114       v115      v116       v117      v118          v119  \\\n",
       "0  15.634907   2.857144  1.951220   6.592012  5.909091 -6.297423e-07   \n",
       "1  10.308044        NaN       NaN  10.595357       NaN           NaN   \n",
       "2  11.205561  12.941177  3.129253   3.478911  6.233767 -2.792745e-07   \n",
       "3  13.777666  10.574713  1.511063   4.949609  7.180722  5.655086e-01   \n",
       "4  14.097099        NaN       NaN        NaN       NaN           NaN   \n",
       "5  15.750502        NaN       NaN   8.851677       NaN           NaN   \n",
       "6   9.010082   8.543690  1.349693  12.168719  6.593406  1.532727e+00   \n",
       "7  18.705610        NaN       NaN        NaN       NaN           NaN   \n",
       "8  12.536835   8.333332  1.931034   3.419186  7.804877  5.182423e-01   \n",
       "9  13.434123  10.700001  1.270491  10.719493  8.174604  8.931283e+00   \n",
       "\n",
       "       v120      v121      v122      v123      v124 v125      v126      v127  \\\n",
       "0  1.059603  0.803572  8.000000  1.989780  0.035754   AU  1.804126  3.113719   \n",
       "1       NaN       NaN       NaN       NaN  0.598896   AF       NaN       NaN   \n",
       "2  2.138728  2.238806  9.333333  2.477596  0.013452   AE  1.773709  3.922193   \n",
       "3  1.166281  1.956521  7.018256  1.812795  0.002267   CJ  1.415230  2.954381   \n",
       "4       NaN       NaN       NaN       NaN       NaN    Z       NaN       NaN   \n",
       "5       NaN       NaN       NaN       NaN  0.049861    X       NaN       NaN   \n",
       "6  0.846716  2.232558  3.476299  1.992594  0.083758   BJ  3.276100  1.623298   \n",
       "7       NaN       NaN       NaN       NaN       NaN   BY       NaN       NaN   \n",
       "8  1.414142  1.276595  8.148148  1.875560  0.018659    S  1.159637  5.582865   \n",
       "9  0.434782  2.715964  7.325843  4.896617  0.008944    E  1.344550  1.601176   \n",
       "\n",
       "       v128  v129      v130      v131  \n",
       "0  2.024285     0  0.636365  2.857144  \n",
       "1  1.957825     0       NaN       NaN  \n",
       "2  1.120468     2  0.883118  1.176472  \n",
       "3  1.990847     1  1.677108  1.034483  \n",
       "4       NaN     0       NaN       NaN  \n",
       "5  1.536222     0       NaN       NaN  \n",
       "6  2.266575     0  2.263736  0.970873  \n",
       "7       NaN     0       NaN       NaN  \n",
       "8  1.105283     0  1.170731  3.333334  \n",
       "9  1.928009     0  3.174603  1.000000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns',200)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Check columns with string labels and also print number of unique labels. \n",
    "\n",
    "We will encode the class labels as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in column v3: 4\n",
      "Labels in column v22: 18211\n",
      "Labels in column v24: 5\n",
      "Labels in column v30: 8\n",
      "Labels in column v31: 4\n",
      "Labels in column v47: 10\n",
      "Labels in column v52: 13\n",
      "Labels in column v56: 123\n",
      "Labels in column v66: 3\n",
      "Labels in column v71: 9\n",
      "Labels in column v74: 3\n",
      "Labels in column v75: 4\n",
      "Labels in column v79: 18\n",
      "Labels in column v91: 8\n",
      "Labels in column v107: 8\n",
      "Labels in column v110: 3\n",
      "Labels in column v112: 23\n",
      "Labels in column v113: 37\n",
      "Labels in column v125: 91\n"
     ]
    }
   ],
   "source": [
    "for i in df_train.columns:\n",
    "    if df_train[i].dtype == 'O':\n",
    "        print 'Labels in column %s:' % i, len(np.unique(df_train[i]))\n",
    "        class_mapping = {label:idx for idx,label in enumerate(np.unique(df_train[i]))}\n",
    "        df_train[i] = df_train[i].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['v22'].dtype"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Check number of Nans per feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID            0\n",
       "target        0\n",
       "v1        49832\n",
       "v2        49796\n",
       "v3            0\n",
       "v4        49796\n",
       "v5        48624\n",
       "v6        49832\n",
       "v7        49832\n",
       "v8        48619\n",
       "v9        49851\n",
       "v10          84\n",
       "v11       49836\n",
       "v12          86\n",
       "v13       49832\n",
       "v14           4\n",
       "v15       49836\n",
       "v16       49895\n",
       "v17       49796\n",
       "v18       49832\n",
       "v19       49843\n",
       "v20       49840\n",
       "v21         611\n",
       "v22           0\n",
       "v23       50675\n",
       "v24           0\n",
       "v25       48619\n",
       "v26       49832\n",
       "v27       49832\n",
       "v28       49832\n",
       "          ...  \n",
       "v102      51316\n",
       "v103      49832\n",
       "v104      49832\n",
       "v105      48658\n",
       "v106      49796\n",
       "v107          0\n",
       "v108      48624\n",
       "v109      48624\n",
       "v110          0\n",
       "v111      49832\n",
       "v112          0\n",
       "v113          0\n",
       "v114         30\n",
       "v115      49895\n",
       "v116      49836\n",
       "v117      48624\n",
       "v118      49843\n",
       "v119      50680\n",
       "v120      49836\n",
       "v121      49840\n",
       "v122      49851\n",
       "v123      50678\n",
       "v124      48619\n",
       "v125          0\n",
       "v126      49832\n",
       "v127      49832\n",
       "v128      48624\n",
       "v129          0\n",
       "v130      49843\n",
       "v131      49895\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples (rows): 114321\n"
     ]
    }
   ],
   "source": [
    "print 'Number of samples (rows): %1.f' % len(df_train['v1'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Remove columns with more than some threshold NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_pruned = df_train.dropna(thresh = int(0.75*114321), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_pruned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>v3</th>\n",
       "      <th>v10</th>\n",
       "      <th>v12</th>\n",
       "      <th>v14</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v24</th>\n",
       "      <th>v30</th>\n",
       "      <th>v31</th>\n",
       "      <th>v34</th>\n",
       "      <th>v38</th>\n",
       "      <th>v40</th>\n",
       "      <th>v47</th>\n",
       "      <th>v50</th>\n",
       "      <th>v52</th>\n",
       "      <th>v56</th>\n",
       "      <th>v62</th>\n",
       "      <th>v66</th>\n",
       "      <th>v71</th>\n",
       "      <th>v72</th>\n",
       "      <th>v74</th>\n",
       "      <th>v75</th>\n",
       "      <th>v79</th>\n",
       "      <th>v91</th>\n",
       "      <th>v107</th>\n",
       "      <th>v110</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v114</th>\n",
       "      <th>v125</th>\n",
       "      <th>v129</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.503281</td>\n",
       "      <td>6.085711</td>\n",
       "      <td>11.636387</td>\n",
       "      <td>7.730923</td>\n",
       "      <td>16671</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.270147</td>\n",
       "      <td>0</td>\n",
       "      <td>7.711453</td>\n",
       "      <td>2</td>\n",
       "      <td>0.899420</td>\n",
       "      <td>7</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15.634907</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>6.507647</td>\n",
       "      <td>11.636386</td>\n",
       "      <td>6.763110</td>\n",
       "      <td>7734</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.615077</td>\n",
       "      <td>0</td>\n",
       "      <td>14.305766</td>\n",
       "      <td>4</td>\n",
       "      <td>1.379210</td>\n",
       "      <td>7</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>10.308044</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>6.384670</td>\n",
       "      <td>9.603542</td>\n",
       "      <td>5.245035</td>\n",
       "      <td>7087</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.043864</td>\n",
       "      <td>0</td>\n",
       "      <td>13.077201</td>\n",
       "      <td>2</td>\n",
       "      <td>0.604504</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>11.205561</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.542669</td>\n",
       "      <td>9.646653</td>\n",
       "      <td>14.094723</td>\n",
       "      <td>7.517125</td>\n",
       "      <td>1511</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8.703550</td>\n",
       "      <td>0</td>\n",
       "      <td>11.523045</td>\n",
       "      <td>2</td>\n",
       "      <td>3.329176</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>13.777666</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>6.320087</td>\n",
       "      <td>10.991098</td>\n",
       "      <td>6.414567</td>\n",
       "      <td>8038</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.083151</td>\n",
       "      <td>0</td>\n",
       "      <td>10.138920</td>\n",
       "      <td>8</td>\n",
       "      <td>1.364536</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>14.097099</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target  v3       v10       v12        v14       v21    v22  v24  v30  \\\n",
       "0   3       1   3  0.503281  6.085711  11.636387  7.730923  16671    2    3   \n",
       "1   4       1   3  1.312910  6.507647  11.636386  6.763110   7734    2    3   \n",
       "2   5       1   3  0.765864  6.384670   9.603542  5.245035   7087    4    0   \n",
       "3   6       1   3  6.542669  9.646653  14.094723  7.517125   1511    3    3   \n",
       "4   8       1   3  1.050328  6.320087  10.991098  6.414567   8038    4    0   \n",
       "\n",
       "   v31       v34  v38        v40  v47       v50  v52  v56  v62  v66  v71  v72  \\\n",
       "0    1  7.270147    0   7.711453    2  0.899420    7   86    1    2    4    1   \n",
       "1    1  3.615077    0  14.305766    4  1.379210    7  102    2    0    4    2   \n",
       "2    1  4.043864    0  13.077201    2  0.604504    6   18    1    0    1    3   \n",
       "3    2  8.703550    0  11.523045    2  3.329176    8   48    1    0    4    2   \n",
       "4    1  6.083151    0  10.138920    8  1.364536    8    0    1    2    4    1   \n",
       "\n",
       "   v74  v75  v79  v91  v107  v110  v112  v113       v114  v125  v129  \n",
       "0    1    3    4    1     5     1    15     0  15.634907    22     0  \n",
       "1    1    3    3    2     2     0    21    18  10.308044     7     0  \n",
       "2    1    1    4    7     3     1    19     0  11.205561     6     2  \n",
       "3    1    3    1    2     2     1    10     0  13.777666    65     1  \n",
       "4    1    3    2    7     3     0    20    18  14.097099    90     0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pruned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID          0\n",
       "target      0\n",
       "v3          0\n",
       "v10        84\n",
       "v12        86\n",
       "v14         4\n",
       "v21       611\n",
       "v22         0\n",
       "v24         0\n",
       "v30         0\n",
       "v31         0\n",
       "v34       111\n",
       "v38         0\n",
       "v40       111\n",
       "v47         0\n",
       "v50        86\n",
       "v52         0\n",
       "v56         0\n",
       "v62         0\n",
       "v66         0\n",
       "v71         0\n",
       "v72         0\n",
       "v74         0\n",
       "v75         0\n",
       "v79         0\n",
       "v91         0\n",
       "v107        0\n",
       "v110        0\n",
       "v112        0\n",
       "v113        0\n",
       "v114       30\n",
       "v125        0\n",
       "v129        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pruned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = df_train_pruned.iloc[:,2:].values\n",
    "y_train = df_train_pruned.iloc[:,1].values\n",
    "#y_train = y_train.reshape(y_train.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114321,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114321, 31)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imr = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imr.fit(X_train)\n",
    "X_train_im = imr.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.        ,   0.50328147,   6.08571076, ...,  15.6349074 ,\n",
       "         22.        ,   0.        ],\n",
       "       [  3.        ,   1.31290992,   6.50764678, ...,  10.30804351,\n",
       "          7.        ,   0.        ],\n",
       "       [  3.        ,   0.76586397,   6.38467003, ...,  11.20556132,\n",
       "          6.        ,   2.        ],\n",
       "       ..., \n",
       "       [  3.        ,   2.07877492,   6.6989251 , ...,   8.89313389,\n",
       "         81.        ,   2.        ],\n",
       "       [  3.        ,   1.29102858,   6.69220436, ...,  12.38111312,\n",
       "         51.        ,   0.        ],\n",
       "       [  3.        ,   0.85339132,   6.30639645, ...,  14.63529757,\n",
       "         86.        ,   0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.        ,   0.50328147,   6.08571076, ...,  15.6349074 ,\n",
       "         22.        ,   0.        ],\n",
       "       [  3.        ,   1.31290992,   6.50764678, ...,  10.30804351,\n",
       "          7.        ,   0.        ],\n",
       "       [  3.        ,   0.76586397,   6.38467003, ...,  11.20556132,\n",
       "          6.        ,   2.        ],\n",
       "       ..., \n",
       "       [  3.        ,   2.07877492,   6.6989251 , ...,   8.89313389,\n",
       "         81.        ,   2.        ],\n",
       "       [  3.        ,   1.29102858,   6.69220436, ...,  12.38111312,\n",
       "         51.        ,   0.        ],\n",
       "       [  3.        ,   0.85339132,   6.30639645, ...,  14.63529757,\n",
       "         86.        ,   0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection w/ SBS\n",
    "### (Warning: This takes a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sys\n",
    "\n",
    "class SBS():\n",
    "    def __init__(self, estimator, k_features, scoring=accuracy_score,\n",
    "                 test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "                train_test_split(X, y, test_size=self.test_size, \n",
    "                                 random_state=self.random_state)\n",
    "\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train, \n",
    "                                 X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "\n",
    "        while dim > self.k_features:\n",
    "                        \n",
    "            sys.stderr.write('\\rIteration: %d/%d' % (dim, self.k_features))\n",
    "            sys.stderr.flush()\n",
    "            \n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            for p in combinations(self.indices_, r=dim-1):\n",
    "                score = self._calc_score(X_train, y_train, \n",
    "                                         X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's standardize the feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stdsc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114321, 31)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std = stdsc.fit_transform(X_train_im)\n",
    "X_train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18261343, -0.99017125, -0.86089917, ...,  0.78858071,\n",
       "        -0.97301635, -0.44737166],\n",
       "       [ 0.18261343, -0.40915114, -0.40432896, ..., -1.25012396,\n",
       "        -1.56343976, -0.44737166],\n",
       "       [ 0.18261343, -0.80173208, -0.53740013, ..., -0.90662471,\n",
       "        -1.60280132,  2.43755476],\n",
       "       ..., \n",
       "       [ 0.18261343,  0.14046265, -0.19734976, ..., -1.79164011,\n",
       "         1.34931571,  2.43755476],\n",
       "       [ 0.18261343, -0.42485402, -0.20462216, ..., -0.45671591,\n",
       "         0.1684689 , -0.44737166],\n",
       "       [ 0.18261343, -0.73891913, -0.62209872, ...,  0.40600866,\n",
       "         1.54612351, -0.44737166]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sbs = SBS(knn,k_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sbs.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting performance of feature subsets\n",
    "k_feat = [len(k) for k in sbs.subsets_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(k_feat,sbs.scores_,marker='o')\n",
    "plt.ylim([0.5,1.1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k5 = list(sbs.subsets_[6])\n",
    "print(df_train_pruned.columns[1:][k5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn.fit(X_train_std, y_train)\n",
    "print('Training accuracy:', knn.score(X_train_std, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature Selection w/ L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "lr.fit(X_train_std, y_train)\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "weights, params = [],[]\n",
    "\n",
    "## Iterate over regularization paramter C\n",
    "for c in np.arange(-4,6):\n",
    "    lr = LogisticRegression(penalty='l1', C=10**c, random_state=0)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    weights.append(lr.coef_[0])\n",
    "    params.append(10**c)\n",
    "    \n",
    "weights = np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in range(weights.shape[1]):\n",
    "    plt.plot(params, weights[:,column], \n",
    "             label=df_train_pruned.columns[column+2])\n",
    "    \n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-5), 10**5])\n",
    "plt.ylabel('weight coefficient')\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "ax.legend(loc='upper center', \n",
    "          bbox_to_anchor=(1.38, 1.03),\n",
    "          ncol=1, fancybox=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr.n_iter_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature Selection w/ random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76119872989214576"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train==1].sum()/float(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2388012701078542"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[y_train==0])/float(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_labels = df_train_pruned.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100,\n",
    "                                random_state=0,\n",
    "                                n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest.fit(X_train_im, y_train)\n",
    "importances = forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) v50                            0.120566\n",
      " 2) v12                            0.067445\n",
      " 3) v21                            0.062100\n",
      " 4) v22                            0.062003\n",
      " 5) v114                           0.061961\n",
      " 6) v34                            0.061387\n",
      " 7) v10                            0.061168\n",
      " 8) v40                            0.060484\n",
      " 9) v14                            0.057958\n",
      "10) v125                           0.051472\n",
      "11) v112                           0.039851\n",
      "12) v52                            0.038558\n",
      "13) v56                            0.028515\n",
      "14) v113                           0.025697\n",
      "15) v66                            0.024337\n",
      "16) v107                           0.022658\n",
      "17) v91                            0.022233\n",
      "18) v30                            0.019619\n",
      "19) v24                            0.018473\n",
      "20) v79                            0.016378\n",
      "21) v47                            0.013559\n",
      "22) v62                            0.012518\n",
      "23) v72                            0.010453\n",
      "24) v71                            0.010394\n",
      "25) v110                           0.008049\n",
      "26) v75                            0.007478\n",
      "27) v129                           0.006612\n",
      "28) v31                            0.005641\n",
      "29) v38                            0.001451\n",
      "30) v74                            0.000590\n",
      "31) v3                             0.000393\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            feat_labels[indices[f]], \n",
    "                            importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 31)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFqCAYAAADP4flsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABshmAEAsJH/D6eKGYG8hXvxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9e9f71ec>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Feature Importances')\n",
    "plt.bar(range(X_train.shape[1]), \n",
    "        importances[indices],\n",
    "        color='lightblue', \n",
    "        align='center')\n",
    "\n",
    "plt.xticks(range(X_train.shape[1]), \n",
    "           feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's use only features with importance >0.04 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ID', u'target', u'v3', u'v10', u'v12', u'v14', u'v21', u'v22', u'v24',\n",
       "       u'v30', u'v31', u'v34', u'v38', u'v40', u'v47', u'v50', u'v52', u'v56',\n",
       "       u'v62', u'v66', u'v71', u'v72', u'v74', u'v75', u'v79', u'v91', u'v107',\n",
       "       u'v110', u'v112', u'v113', u'v114', u'v125', u'v129'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pruned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['target','v50','v12','v21','v22',\n",
    "                 'v114','v34','v10','v40','v14','v125',\n",
    "                 'v112','v52']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_slimmed = df_train_pruned[features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>v50</th>\n",
       "      <th>v12</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v114</th>\n",
       "      <th>v34</th>\n",
       "      <th>v10</th>\n",
       "      <th>v40</th>\n",
       "      <th>v14</th>\n",
       "      <th>v125</th>\n",
       "      <th>v112</th>\n",
       "      <th>v52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.899420</td>\n",
       "      <td>6.085711</td>\n",
       "      <td>7.730923</td>\n",
       "      <td>16671</td>\n",
       "      <td>15.634907</td>\n",
       "      <td>7.270147</td>\n",
       "      <td>0.503281</td>\n",
       "      <td>7.711453</td>\n",
       "      <td>11.636387</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.379210</td>\n",
       "      <td>6.507647</td>\n",
       "      <td>6.763110</td>\n",
       "      <td>7734</td>\n",
       "      <td>10.308044</td>\n",
       "      <td>3.615077</td>\n",
       "      <td>1.312910</td>\n",
       "      <td>14.305766</td>\n",
       "      <td>11.636386</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.604504</td>\n",
       "      <td>6.384670</td>\n",
       "      <td>5.245035</td>\n",
       "      <td>7087</td>\n",
       "      <td>11.205561</td>\n",
       "      <td>4.043864</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>13.077201</td>\n",
       "      <td>9.603542</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3.329176</td>\n",
       "      <td>9.646653</td>\n",
       "      <td>7.517125</td>\n",
       "      <td>1511</td>\n",
       "      <td>13.777666</td>\n",
       "      <td>8.703550</td>\n",
       "      <td>6.542669</td>\n",
       "      <td>11.523045</td>\n",
       "      <td>14.094723</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.364536</td>\n",
       "      <td>6.320087</td>\n",
       "      <td>6.414567</td>\n",
       "      <td>8038</td>\n",
       "      <td>14.097099</td>\n",
       "      <td>6.083151</td>\n",
       "      <td>1.050328</td>\n",
       "      <td>10.138920</td>\n",
       "      <td>10.991098</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target       v50       v12       v21    v22       v114       v34       v10  \\\n",
       "0       1  0.899420  6.085711  7.730923  16671  15.634907  7.270147  0.503281   \n",
       "1       1  1.379210  6.507647  6.763110   7734  10.308044  3.615077  1.312910   \n",
       "2       1  0.604504  6.384670  5.245035   7087  11.205561  4.043864  0.765864   \n",
       "3       1  3.329176  9.646653  7.517125   1511  13.777666  8.703550  6.542669   \n",
       "4       1  1.364536  6.320087  6.414567   8038  14.097099  6.083151  1.050328   \n",
       "\n",
       "         v40        v14  v125  v112  v52  \n",
       "0   7.711453  11.636387    22    15    7  \n",
       "1  14.305766  11.636386     7    21    7  \n",
       "2  13.077201   9.603542     6    19    6  \n",
       "3  11.523045  14.094723    65    10    8  \n",
       "4  10.138920  10.991098    90    20    8  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_slimmed.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we have a pruned data set with only the most important features and with imputed values (ie no NaNs), let's select a model."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First, we'll re-define X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = df_train_slimmed.iloc[:,1:], df_train_slimmed.iloc[:,0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Impute the new training feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imr = Imputer(missing_values='NaN',strategy='mean', axis=0)\n",
    "imr = imr.fit(X_train)\n",
    "X_train = imr.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114321, 12)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114321,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's first standardize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.89942   ,   6.08571076,   7.73092331, ...,  22.        ,\n",
       "         15.        ,   7.        ],\n",
       "       [  1.37921007,   6.50764678,   6.7631095 , ...,   7.        ,\n",
       "         21.        ,   7.        ],\n",
       "       [  0.60450408,   6.38467003,   5.24503529, ...,   6.        ,\n",
       "         19.        ,   6.        ],\n",
       "       ..., \n",
       "       [  2.41068147,   6.6989251 ,   6.57062511, ...,  81.        ,\n",
       "         18.        ,   4.        ],\n",
       "       [  0.82165655,   6.69220436,   7.73075117, ...,  51.        ,\n",
       "          1.        ,  10.        ],\n",
       "       [  1.00066097,   6.30639645,   7.49600008, ...,  86.        ,\n",
       "          1.        ,   7.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.51789775, -0.86089917,  0.65568076, ..., -0.97301635,\n",
       "         0.89944058,  0.12854635],\n",
       "       [-0.10707805, -0.40432896, -0.24932807, ..., -1.56343976,\n",
       "         1.91542877,  0.12854635],\n",
       "       [-0.77041918, -0.53740013, -1.66888889, ..., -1.60280132,\n",
       "         1.57676604, -0.16203454],\n",
       "       ..., \n",
       "       [ 0.77611819, -0.19734976, -0.42932144, ...,  1.34931571,\n",
       "         1.40743467, -0.74319631],\n",
       "       [-0.58448262, -0.20462216,  0.65551979, ...,  0.1684689 ,\n",
       "        -1.47119851,  1.000289  ],\n",
       "       [-0.43121029, -0.62209872,  0.43600256, ...,  1.54612351,\n",
       "        -1.47119851,  0.12854635]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.594282765196\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', C=0.1, class_weight='balanced')\n",
    "lr.fit(X_train_std,y_train)\n",
    "print 'Training accuracy:', lr.score(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17572518])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's look at a validation curve for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.learning_curve import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_scores, test_scores = validation_curve(estimator=lr,\n",
    "                                            X=X_train_std,\n",
    "                                            y=y_train,\n",
    "                                            param_name='C',\n",
    "                                            param_range=param_range,\n",
    "                                            cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0.85)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFpCAYAAACWO/HdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiIRSj0RURELOL/B2ftk2IxDpsJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9ea0640c>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_mean = np.mean(train_scores,axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(param_range, train_mean, \n",
    "         color='blue', marker='o', \n",
    "         markersize=5, label='training accuracy')\n",
    "\n",
    "plt.fill_between(param_range, train_mean + train_std,\n",
    "                 train_mean - train_std, alpha=0.15,\n",
    "                 color='blue')\n",
    "\n",
    "plt.plot(param_range, test_mean, \n",
    "         color='green', linestyle='--', \n",
    "         marker='s', markersize=5, \n",
    "         label='validation accuracy')\n",
    "\n",
    "plt.fill_between(param_range, \n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std, \n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.4,0.85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19745  7555]\n",
      " [38828 48193]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x9ea06f4c>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAC4CAYAAABKD8ZJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x97af18ec>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#lr.fit(X_train_std, y_train)\n",
    "y_pred = lr.predict(X_train_std)\n",
    "confmat = confusion_matrix(y_true=y_train, y_pred=y_pred)\n",
    "print (confmat)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So logistic regression isn't doing a great job. Let's try another model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, \n",
    "                                random_state=0,\n",
    "                                class_weight='balanced',\n",
    "                                max_depth=4,\n",
    "                                n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=4, max_features='auto',\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_pred = forest.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest training accuracy 0.629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print 'Random Forest training accuracy %.3f' % (accuracy_score(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosted decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy',\n",
    "                              random_state=0,\n",
    "                              class_weight='balanced')\n",
    "\n",
    "ada = AdaBoostClassifier(base_estimator=tree, \n",
    "                         n_estimators=100,\n",
    "                         learning_rate=0.1,\n",
    "                         random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = tree.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision training accuracy 1.000\n"
     ]
    }
   ],
   "source": [
    "tree_train = accuracy_score(y_train, y_train_pred)\n",
    "print 'Decision training accuracy %.3f' % (tree_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada = ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = ada.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost training accuracy 1.000\n"
     ]
    }
   ],
   "source": [
    "ada_train = accuracy_score(y_train, y_train_pred) \n",
    "print 'AdaBoost training accuracy %.3f' % (ada_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
